{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A data analysis of the NYC taxi rides - part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in part 1 that using a static visualisation for a flow, as well as loading the data into memory has its limits.\n",
    "In this notebook, we will go through the following steps required to generate animations and heat maps to visualise the flow of passengers of the yello taxis in 2018:\n",
    "- set up the database\n",
    "- query the data\n",
    "- create an animation\n",
    "- create a heat map\n",
    "\n",
    "As a reminder, we are trying to answer the following questions:\n",
    "- Can we see trends in the flow of passengers in 2018?\n",
    "- Is there a difference on holidays, hottest or coldest day of the year?\n",
    "- Is there a difference between weekdays and weekends?\n",
    "- Depending on the zone we look at, where are people most likely to come from? To go to? Is it different between weekdays and weekends?\n",
    "\n",
    "What we are targeting is:\n",
    "- to have an animation for the whole year 2018, with 1-2 seconds of animation showing the flow of passengers every day (i.e the movement of dots on the map representing passengers going from one point to another)\n",
    "- to have an animation only for aggregated weekdays and weekends data - which would be represented by 1-2 seconds per week, with either just weekdays or just weekends.\n",
    "- to have a heat map showing for each zone the difference between the average of *incoming* passengers between weekdays and weekends (so for each zone we have a map, that uses a color code to show where people are mostly coming from, and whether it is more on weekdays or on weekends).\n",
    "- to have a heat map showing for each zone the difference between the average of *outgoing* passengers between weekdays and weekends (so for each zone we have a map, that uses a color code to show where people are mostly going to, and whether it is more on weekdays or on weekends).\n",
    "\n",
    "We should be able to identify trends from those visualizations in order to answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Database set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environment details and cleaning steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using MariaDB (5.7.18), we created three tables:\n",
    "- taxi_rides_2018 (primary key: auto-increment ID)\n",
    "- taxi_rides_2017 (primary key: increment ID)\n",
    "- taxi_zone_lookup_table (primary key: LocationID)\n",
    "\n",
    "As an idea of the size of the table, taxi_rides_2018 has about 97 million rows avec cleanup (about 100M beforehand). \n",
    "For both 2017 and 2018, we defined additional indexes to speed up the query:\n",
    "- PULocationID\n",
    "- DOLocationID\n",
    "- Date (column added)\n",
    "- Weekday (column added)\n",
    "\n",
    "We decided not to join the zone lookup table with the trips tables, but to do the join when querying the data.\n",
    "\n",
    "We performed a few cleaning steps:\n",
    "- Remove rows with values = 0 :\n",
    "    - PULocationID\n",
    "    - DOLocationID\n",
    "    - passenger_count\n",
    "    - tpep_pickup_datetime\n",
    "    - tpep_dropff_datetime\n",
    "- Remove rows with unused values:\n",
    "    - PULocationID equals to 264 or 265 (unknown zone id)\n",
    "    - DOLocationID equals to 264 or 265 (unknown zone id)\n",
    "- Remove rows with negative values:\n",
    "    - fare_amount\n",
    "    - extra\n",
    "    - mta_tax\n",
    "    - tip_amount\n",
    "    - tolls_amount\n",
    "    - improvement_surcharge\n",
    "- Add a column with only the date (as an index of the table)\n",
    "- Add a column with the weekday (as an index of the table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Queries for table creation and clean up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of the queries (example of 2017)\n",
    "\n",
    "#Create a table with all columns and indexes\n",
    "CREATE TABLE taxi_rides_2017 (\n",
    "    id INT NOT NULL AUTO_INCREMENT FIRST,\n",
    "    VendorID INTEGER NOT NULL,\n",
    "    tpep_pickup_datetime TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    tpep_dropoff_datetime TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    pickup_date DATE NULL,\n",
    "    pickup_weekday INTEGER NOT NULL,\n",
    "    dropoff_date DATE NULL,\n",
    "    dropoff_weekday INTEGER NOT NULL,\n",
    "    passenger_count INTEGER NULL,\n",
    "    trip_distance FLOAT NULL,\n",
    "    RatecodeID INTEGER NOT NULL,\n",
    "    store_and_fwd_flag CHARACTER(1) NOT NULL,\n",
    "    PULocationID INTEGER NOT NULL,\n",
    "    DOLocationID INTEGER NOT NULL,\n",
    "    payment_type INTEGER NOT NULL,\n",
    "    fare_amount FLOAT NULL,\n",
    "    extra FLOAT NULL,\n",
    "    mta_tax FLOAT NULL,\n",
    "    tip_amount FLOAT NULL,\n",
    "    tolls_amount FLOAT NULL,\n",
    "    improvement_surcharge FLOAT NULL,\n",
    "    total_amount FLOAT NULL,\n",
    "    PRIMARY KEY (id),\n",
    "    INDEX pickup_date (pickup_date),\n",
    "    INDEX pickup_weekday (pickup_weekday),\n",
    "    INDEX dropoff_date (dropoff_date),\n",
    "    INDEX dropoff_weekday (dropoff_weekday),\n",
    "    FOREIGN KEY (PULocationID) REFERENCES taxi_zone_lookup_table(LocationID),\n",
    "    FOREIGN KEY (DOLocationID) REFERENCES taxi_zone_lookup_table(LocationID)\n",
    ");\n",
    "\n",
    "#Load the data - merged file for a year\n",
    "LOAD DATA LOCAL INFILE '/Users/acoullandreau/Desktop/Taxi_rides_DS/2017/merged_2017.csv' \n",
    "INTO TABLE taxi_rides_2017 \n",
    "FIELDS TERMINATED BY ',' \n",
    "LINES TERMINATED BY '\\r\\n'\n",
    "IGNORE 1 ROWS#Ignore header\n",
    "(VendorID,tpep_pickup_datetime,tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID,\tDOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount) \n",
    "SET id=null,#sets ID to auto-increment\n",
    "pickup_date = DATE(tpep_pickup_datetime),\n",
    "pickup_weekday = WEEKDAY(tpep_pickup_datetime), \n",
    "dropoff_date = DATE(tpep_dropoff_datetime), \n",
    "dropoff_weekday = WEEKDAY(tpep_dropoff_datetime)\n",
    ";\n",
    "\n",
    "#Clean up the data\n",
    "DELETE FROM nyc_taxi_rides.taxi_rides_2017 \n",
    "WHERE PULocationID IN (0, 264, 265) \n",
    "OR DOLocationID IN (0, 264, 265) \n",
    "OR passenger_count  = 0 \n",
    "OR tpep_pickup_datetime = 0 \n",
    "OR tpep_dropoff_datetime  = 0 \n",
    "OR fare_amount <0 \n",
    "OR extra<0 \n",
    "OR mta_tax<0 \n",
    "OR tip_amount<0 \n",
    "OR tolls_amount<0 \n",
    "OR improvement_surcharge<0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the database was up and ready, we could start writting the set of functions and the python script that would allow us to connect to the database, query the data, process it and render it, either in the form of an animation (video) or a heat map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Building a python script - part 1 (base map and query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:*\n",
    "\n",
    "*The code is documented in this notebook, with comments inside each function, as well as on GitHub, where both a documentation and a graph of connection of each function to the other are available. The idea of the graph is to illustrate the logical flow of the script.*\n",
    "\n",
    "To start with, we will need to:\n",
    "- process the shapefile\n",
    "- render a base map\n",
    "- prepare the query\n",
    "- connect to the database and execute the query\n",
    "\n",
    "The functions below can be used to go through each of these steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import to be able to run the code below\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import shapefile as shp\n",
    "from pyproj import Proj, transform\n",
    "import cv2\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shp_to_df(sf):\n",
    " \n",
    "    fields = [x[0] for x in sf.fields][1:]\n",
    "    records = sf.records()\n",
    "    shps = [s.points for s in sf.shapes()]\n",
    "    df = pd.DataFrame(columns=fields, data=records)\n",
    "    df = df.assign(coords=shps)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_centroid(points):\n",
    "\n",
    "    x_sum = 0\n",
    "    y_sum = 0\n",
    "    for coords in points:\n",
    "        x_sum += coords[0]\n",
    "        y_sum += coords[1]\n",
    "        \n",
    "    x_mean = x_sum/len(points)\n",
    "    y_mean = y_sum/len(points)\n",
    "    \n",
    "    return x_mean, y_mean\n",
    "\n",
    "\n",
    "def calculate_boundaries(points):\n",
    "  \n",
    "    x_max = -99999999\n",
    "    x_min = 99999999\n",
    "    y_max = -99999999\n",
    "    y_min = 99999999\n",
    "    \n",
    "    for coords in points:\n",
    "        if coords[0] > x_max:\n",
    "            x_max = coords[0]\n",
    "        if coords[0] < x_min:\n",
    "            x_min = coords[0]\n",
    "        if coords[1] > y_max:\n",
    "            y_max = coords[1]\n",
    "        if coords[1] < y_min:\n",
    "            y_min = coords[1]\n",
    "        \n",
    "    max_bound = (x_max, y_max)\n",
    "    min_bound = (x_min, y_min)\n",
    "    \n",
    "    return max_bound, min_bound\n",
    "\n",
    "\n",
    "def process_shape_boundaries(df_sf, sf):\n",
    "    \n",
    "    shape_dict = {}\n",
    "    index_list = df_sf.index.tolist()\n",
    "    \n",
    "    for zone_id in index_list:\n",
    "        #for each zone id available in the shapefile\n",
    "        if zone_id not in shape_dict:\n",
    "            #we only process the coordinates if it is not yet included in the dictionary\n",
    "            shape_zone = sf.shape(zone_id)\n",
    "            \n",
    "            points = [(i[0], i[1]) for i in shape_zone.points]\n",
    "            \n",
    "            x_center, y_center = calculate_centroid(points)\n",
    "            max_bound, min_bound = calculate_boundaries(points)\n",
    "            \n",
    "            #we add to the dictionary, for the zone id, the shape boundaries as well\n",
    "            #as the coordinates of the center of the shape znd the zone extreme boundaries\n",
    "            shape_dict[zone_id] = {}\n",
    "            shape_dict[zone_id]['points'] = points\n",
    "            shape_dict[zone_id]['center'] = (x_center, y_center)\n",
    "            shape_dict[zone_id]['max_bound'] = max_bound\n",
    "            shape_dict[zone_id]['min_bound'] = min_bound\n",
    "            \n",
    "    return shape_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_coords(shape_dict):\n",
    "    \n",
    "    all_max_bound = []\n",
    "    all_min_bound = []\n",
    "    \n",
    "    for zone in shape_dict:\n",
    "        zone_shape = shape_dict[zone]\n",
    "        max_bound_zone = zone_shape['max_bound']\n",
    "        min_bound_zone = zone_shape['min_bound']\n",
    "        all_max_bound.append(max_bound_zone)\n",
    "        all_min_bound.append(min_bound_zone)\n",
    "    \n",
    "    map_max_bound, unused_max = calculate_boundaries(all_max_bound)\n",
    "    unused_min, map_min_bound = calculate_boundaries(all_min_bound)\n",
    "    \n",
    "    return map_max_bound, map_min_bound\n",
    "\n",
    "\n",
    "def define_projection(map_max_bound, map_min_bound, image_size):\n",
    "    \n",
    "    #We get the max 'coordinates' for both the target image and the shape we want to draw\n",
    "    image_x_max = image_size[0]\n",
    "    image_y_max = image_size[1]\n",
    "    map_x_max = map_max_bound[0]\n",
    "    map_y_max = map_max_bound[1]\n",
    "    map_x_min = map_min_bound[0]\n",
    "    map_y_min = map_min_bound[1]\n",
    "    \n",
    "    projection = {}\n",
    "\n",
    "    #we check which size is bigger to know based on which axis we want to scale our shape to\n",
    "    #we do the comparison using the aspect ratio expectations (dividing each axis by the\n",
    "    #size of the target axis in the new scale)\n",
    "    if (map_x_max - map_x_min)/image_x_max > (map_y_max - map_y_min)/image_y_max:\n",
    "        conversion = image_x_max / (map_x_max - map_x_min)\n",
    "        axis_to_center = 'y'#we store the axis we will want to center on based on which\n",
    "        #axis we perform the scaling from\n",
    "    else:\n",
    "        conversion = image_y_max / (map_y_max - map_y_min)\n",
    "        axis_to_center = 'x'\n",
    "\n",
    "    projection['image_size'] = image_size\n",
    "    projection['map_max_bound'] = map_max_bound\n",
    "    projection['map_min_bound'] = map_min_bound\n",
    "    projection['conversion'] = conversion\n",
    "    projection['axis_to_center'] = axis_to_center\n",
    "    \n",
    "    return projection\n",
    "\n",
    "\n",
    "def convert_projection(x, y, projection, inverse=False):\n",
    "    \n",
    "    x_min = projection['map_min_bound'][0]\n",
    "    y_min = projection['map_min_bound'][1]\n",
    "    conversion = projection['conversion']\n",
    "    \n",
    "    if inverse == False:\n",
    "        #to be able to center the image, we first translate the coordinates to the origin\n",
    "        x = (x - x_min) *conversion\n",
    "        y = (y - y_min) *conversion\n",
    "    else:\n",
    "        x = (x + x_min) /conversion\n",
    "        y = (y + y_min) /conversion\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def convert_shape_boundaries(zone_shape_dict, projection):\n",
    "    \n",
    "    converted_dict = {}\n",
    "    axis_to_center = projection['axis_to_center']\n",
    "    image_x_max = projection['image_size'][0]\n",
    "    image_y_max = projection['image_size'][1]\n",
    "    map_max_bound_converted = (convert_projection(projection['map_max_bound'][0], projection['map_max_bound'][1], projection))\n",
    "    map_min_bound_converted = (convert_projection(projection['map_min_bound'][0], projection['map_min_bound'][1], projection))\n",
    "    \n",
    "    if axis_to_center == 'x':\n",
    "        center_translation = (image_x_max - (map_max_bound_converted[0] - map_min_bound_converted[0]))/2\n",
    "    else:\n",
    "        center_translation = (image_y_max - (map_max_bound_converted[1] - map_min_bound_converted[1]))/2\n",
    "    \n",
    "    \n",
    "    for zone_id in zone_shape_dict:\n",
    "        curr_shape = zone_shape_dict[zone_id]\n",
    "        \n",
    "        points = curr_shape['points']\n",
    "        x_center = curr_shape['center'][0]\n",
    "        y_center = curr_shape['center'][1]\n",
    "        max_bound = curr_shape['max_bound']\n",
    "        min_bound = curr_shape['min_bound']\n",
    "        \n",
    "        converted_points = []\n",
    "        for point in points:\n",
    "            #we convert the coordinates to the new coordinate system\n",
    "            converted_point = [0, 0] \n",
    "            converted_point[0], converted_point[1] = convert_projection(point[0], point[1], projection)\n",
    "            #we center the map on the axis that was not used to scale the image\n",
    "            if axis_to_center == 'x':\n",
    "                converted_point[0] = converted_point[0] + center_translation\n",
    "            else:\n",
    "                converted_point[1] = converted_point[1] + center_translation\n",
    "            \n",
    "            #we mirror the image to match the axis alignment\n",
    "            converted_point[1] = image_y_max - converted_point[1]\n",
    "            converted_points.append(converted_point)\n",
    "        \n",
    "        #we convert the center and the max and min boundaries\n",
    "        x_center, y_center = calculate_centroid(converted_points)\n",
    "        max_bound = (convert_projection(max_bound[0], max_bound[1], projection))\n",
    "        min_bound = (convert_projection(min_bound[0], min_bound[1], projection))\n",
    "        \n",
    "        \n",
    "        #We edit the dictionary with the new coordinates\n",
    "        converted_dict[zone_id] = {}\n",
    "        converted_dict[zone_id]['points'] = converted_points\n",
    "        converted_dict[zone_id]['center'] = (x_center, y_center)\n",
    "        converted_dict[zone_id]['max_bound'] = max_bound\n",
    "        converted_dict[zone_id]['min_bound'] = min_bound\n",
    "        \n",
    "    return converted_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_set_to_draw(map_type, shape_dict, df_sf, image_size):\n",
    "\n",
    "    #we define if we want to draw the whole map or only a borough (in this case map_type\n",
    "    #should be the borough name)\n",
    "    if map_type == 'total':\n",
    "        shape_dict = shape_dict\n",
    "    else:\n",
    "        #we select the list of zone_id we want to draw that belong only to the targeted \n",
    "        #borough to draw\n",
    "        shape_dict = reduce_shape_dict_to_borough(shape_dict, df_sf, map_type)\n",
    "    \n",
    "    #We define the projection parameters to be able to convert the coordinates into\n",
    "    #the image scale coordinate system\n",
    "    #we convert the coordinates of the shapes to draw\n",
    "    map_max_bound, map_min_bound = find_max_coords(shape_dict)\n",
    "    projection = define_projection(map_max_bound, map_min_bound, image_size)\n",
    "    converted_shape_dict = convert_shape_boundaries(shape_dict, projection)\n",
    "    \n",
    "    return converted_shape_dict, projection\n",
    "\n",
    "\n",
    "def reduce_shape_dict_to_borough(shape_dict, df_sf, borough_name):\n",
    "        \n",
    "    borough_df = df_sf[df_sf['borough']==borough_name]\n",
    "    borough_id = []\n",
    "    for objectid in borough_df.index:\n",
    "        borough_id.append(objectid)\n",
    "    \n",
    "    reduced_shape_dict = {}\n",
    "    #we add to the reduced_shape_dict only the zones belonging to the borough area targeted\n",
    "    for zone_id in borough_id:\n",
    "        reduced_shape_dict[zone_id] = shape_dict[zone_id]\n",
    "    \n",
    "    return reduced_shape_dict\n",
    "\n",
    "\n",
    "def draw_base_map(draw_dict):\n",
    "    \n",
    "    #We extract the variables we will need from the input dictionary\n",
    "    image_size = draw_dict['image_size']\n",
    "    map_type = draw_dict['map_type']\n",
    "    title = draw_dict['title']\n",
    "    shape_dict = draw_dict['shape_dict']\n",
    "    df_sf = draw_dict['df_sf']\n",
    "    render_single_borough = draw_dict['render_single_borough']\n",
    "                    \n",
    "    #first we create a blank image, on which we will draw the base map\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    base_map = np.zeros((height,width,3), np.uint8) #Size of the image 1080 height, 1920 width, 3 channels of colour\n",
    "    base_map[:, :] = [0, 0, 0] #Sets the color to white\n",
    "    \n",
    "    #we isolate the set of shapes we want to draw in the right coordinate system\n",
    "    converted_shape_dict, projection = get_shape_set_to_draw(map_type, shape_dict, df_sf, image_size)\n",
    "    \n",
    "    if render_single_borough == False:\n",
    "        #we use the projection parameters from the borough we want to focus on\n",
    "        #we calculate the coordinates for the whole map\n",
    "        converted_shape_dict = convert_shape_boundaries(shape_dict, projection)\n",
    "        \n",
    "    #we draw each shape of the dictionary on the blank image, \n",
    "    #either the full map or only a borough \n",
    "    for item in converted_shape_dict:\n",
    "        shape = converted_shape_dict[item]\n",
    "        points = shape['points']\n",
    "        pts = np.array(points, np.int32)\n",
    "        cv2.polylines(base_map, [pts], True, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    #we display general text information   \n",
    "    display_general_information_text(base_map, map_type, title)\n",
    "    \n",
    "    return base_map, projection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sql_query(query_dict):\n",
    "\n",
    "    #We extract the variables we will need from the input dictionary\n",
    "    data_table = query_dict['data_table']\n",
    "    lookup_table = query_dict['lookup_table']\n",
    "    aggregated_result = query_dict['aggregated_result']\n",
    "    date = query_dict['date']\n",
    "    filter_query_on_borough = query_dict['filter_query_on_borough']\n",
    "    \n",
    "    #first we synthesise what we want to fetch\n",
    "    if aggregated_result == 'count':\n",
    "        aggregated_result = 'COUNT(passenger_count)'\n",
    "    elif aggregated_result == 'avg':\n",
    "        aggregated_result = 'AVG(passenger_count)'\n",
    "    \n",
    "    #then we work on the 'WHERE' statements and the JOIN \n",
    "    if filter_query_on_borough != False:\n",
    "        query = (\"SELECT pu_id, do_id, aggregated_result FROM (\\\n",
    "                    SELECT PULocationID pu_id, DOLocationID do_id, {0} aggregated_result\\\n",
    "                    FROM {1} tr_2018\\\n",
    "                    WHERE pickup_date = '{2}'\\\n",
    "                    GROUP BY pu_id, do_id\\\n",
    "                    ORDER by aggregated_result\\\n",
    "                ) AS tr_2018\\\n",
    "                 JOIN {3} lookup_pu\\\n",
    "                 ON lookup_pu.LocationID = tr_2018.pu_id \\\n",
    "                 JOIN {3} lookup_do \\\n",
    "                 ON lookup_do.LocationID = tr_2018.do_id \\\n",
    "                 WHERE lookup_pu.borough_name = '{4}' AND lookup_do.borough_name = '{4}'\".format\n",
    "                (aggregated_result, data_table, date, lookup_table, filter_query_on_borough))\n",
    "\n",
    "    else:\n",
    "        query = (\"SELECT PULocationID pu_id, DOLocationID do_id, {0} aggregated_result\\\n",
    "                    FROM {1} AS tr_2018\\\n",
    "                    WHERE pickup_date = '{2}'\\\n",
    "                    GROUP BY pu_id, do_id\".format(aggregated_result, data_table, date))\n",
    "\n",
    "\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sql_query(query, database):\n",
    "\n",
    "    #connect to the database\n",
    "    db = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        passwd=\"dllpsax00\",\n",
    "        database=database\n",
    "        )\n",
    "\n",
    "    #execute the query...\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # ...and store the output\n",
    "    results=[]\n",
    "    for result in cursor:\n",
    "        results.append(result)\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Building a python script - part 2 (animation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we havea base map and the result of the query, we are able to start processing the data to render it in an animation.\n",
    "\n",
    "We will need to:\n",
    "- process the query results\n",
    "- render each point by interpolating its position\n",
    "- render each frame\n",
    "- render the animation\n",
    "\n",
    "The functions below can be used to go through each of these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_next_position(origin_coords, destination_coords, tot_frames, curr_frame):\n",
    "        \n",
    "    #as to perform the arithmetic operations, we convert everything to float for more \n",
    "    #precision\n",
    "    x_origin = float(origin_coords[0])\n",
    "    y_origin = float(origin_coords[1])\n",
    "    x_destination = float(destination_coords[0])\n",
    "    y_destination = float(destination_coords[1])\n",
    "    tot_frames = float(tot_frames - 1)\n",
    "    curr_frame = float(curr_frame)\n",
    "    \n",
    "    delta_x = (x_destination - x_origin)/tot_frames\n",
    "    delta_y = (y_destination - y_origin)/tot_frames\n",
    "    \n",
    "    #the rendering with OpenCV demands integers values for the positioning, so we convert\n",
    "    #w and y to int\n",
    "    new_x = int(x_origin+delta_x*curr_frame)\n",
    "    new_y = int(y_origin+delta_y*curr_frame)\n",
    "    \n",
    "    return new_x, new_y\n",
    "\n",
    "\n",
    "\n",
    "def render_point_on_map(x_point, y_point, weight, base_map, colour):\n",
    "      \n",
    "    cv2.circle(base_map, (x_point,y_point), weight, colour, -1)\n",
    "    \n",
    "    \n",
    "def convert_id_shape(idx, inverse = False):\n",
    "        \n",
    "    if inverse == False:\n",
    "        idx = idx - 1\n",
    "    else:\n",
    "        idx = idx + 1\n",
    "    \n",
    "    return idx\n",
    "    \n",
    "\n",
    "def build_query_dict(render_animation_dict):\n",
    "    \n",
    "    #First, we extract the variables we will need from the input dictionary\n",
    "    time_granularity = render_animation_dict['time_granularity']\n",
    "    data_table = render_animation_dict['data_table']\n",
    "    lookup_table = render_animation_dict['lookup_table']\n",
    "    aggregated_result = render_animation_dict['aggregated_result']\n",
    "    filter_query_on_borough = render_animation_dict['filter_query_on_borough']\n",
    "    \n",
    "    #we instantiate the query_dict and start filling it with query parameters\n",
    "    query_dict = {}\n",
    "    query_dict['data_table'] = data_table\n",
    "    query_dict['lookup_table'] = lookup_table\n",
    "    query_dict['aggregated_result'] = aggregated_result\n",
    "    \n",
    "    #we handle the borough related WHEN statement\n",
    "    if filter_query_on_borough == False:\n",
    "        query_dict['filter_query_on_borough'] = False\n",
    "    else:\n",
    "        query_dict['filter_query_on_borough'] = filter_query_on_borough\n",
    "    \n",
    "    #we handle the time related WHEN statements\n",
    "    period = render_animation_dict['period']\n",
    "    start_date = period[0]\n",
    "    end_date = period[1]\n",
    "        \n",
    "    if start_date == end_date:\n",
    "        query_dict['date'] = start_date\n",
    "\n",
    "    else:\n",
    "        #if the period is more than one date, we will have to loop through the\n",
    "        #date range and render multiple series of 60 frames (1 second at 60 fps per day)\n",
    "        #Thus the loop needs to be handled by the main plotting function, and here we\n",
    "        #simply add a flag to the query dict that will be transformed by the plotting\n",
    "        #function\n",
    "        query_dict['date'] = 'loop_through_period'\n",
    "\n",
    "    #used specifically for the animation logic\n",
    "    if time_granularity == 'specific_weekdays':\n",
    "        specific_weekdays = render_animation_dict['weekdays']\n",
    "        query_dict['specific_weekdays'] = 'on_specific_weekdays'\n",
    "    \n",
    "    #used specifically for the animation logic\n",
    "    elif time_granularity == 'period':\n",
    "        query_dict['specific_weekdays'] = False\n",
    "    \n",
    "    #used specifically for the heat_map logic\n",
    "    elif time_granularity == 'weekdays_vs_weekends':\n",
    "        query_dict['specific_weekdays'] = 'weekdays_vs_weekends'\n",
    "    \n",
    "    return query_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(map_type, weight, max_passenger):\n",
    "    #we normalise the weight of the point based on the max number of passengers\n",
    "    #which means that from one day to another, although the biggest point will have the\n",
    "    #same size, it will not represent the same number of passengers (compromise to\n",
    "    #prevent having huge differences between the points, or squishing too much the scale\n",
    "    #by using a log). \n",
    "    \n",
    "    if map_type != 'total':\n",
    "        weight = weight/max_passenger*20\n",
    "    else:\n",
    "        weight = weight/max_passenger*10\n",
    "\n",
    "    weight = int(weight)\n",
    "\n",
    "    return weight\n",
    "\n",
    "\n",
    "def display_specific_text(rendered_frame, date, map_type, min_pass, max_pass):\n",
    "    #note that these position are based on an image size of [1920, 1080]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    #64, 64, 64\n",
    "    #displays the date and the weekday, and if it is a special date\n",
    "    cv2.putText(rendered_frame, date, (40, 150), font, 1.3, (221, 221, 221), 1, cv2.LINE_AA)\n",
    "    \n",
    "    special_dates_2018 = {'2018-01-01':'New Year', '2018-12-25':'Christmas',\n",
    "                         '2018-02-14':'Valentine\\'s Day', '2018-07-04':'National Day',\n",
    "                         '2018-07-01':'Hottest Day', '2018-01-07':'Coldest Day'}\n",
    "    if date in special_dates_2018:\n",
    "        cv2.putText(rendered_frame, special_dates_2018[date], (40, 200), font, 1.3, (221, 221, 221), 1, cv2.LINE_AA)\n",
    "        \n",
    "    date_timestamp = pd.Timestamp(date)\n",
    "    weekday = date_timestamp.dayofweek\n",
    "    weekdays = {0:'Monday', 1:'Tuesday',2:'Wednesday',3:'Thursday', \n",
    "                4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "    weekday = weekdays[weekday]\n",
    "    cv2.putText(rendered_frame, weekday, (40, 95), font, 1.3, (221, 221, 221), 1, cv2.LINE_AA)\n",
    "\n",
    "    #displays the legend of the size of the circles\n",
    "    cv2.putText(rendered_frame, 'Number of passengers', (35, 380), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    max_weight = compute_weight(map_type, max_pass, max_pass)\n",
    "    cv2.circle(rendered_frame, (40, 420), max_weight, (255, 255, 255), 1)\n",
    "    cv2.putText(rendered_frame, '{} passengers'.format(max_pass), (80, 420), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    min_weight = compute_weight(map_type, min_pass, max_pass)\n",
    "    cv2.circle(rendered_frame, (40, 460), min_weight, (255, 255, 255), 1)\n",
    "    cv2.putText(rendered_frame, '{} passenger'.format(min_pass), (80, 460), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "\n",
    "def display_general_information_text(image, map_type, video_title):\n",
    "\n",
    "    #note that these position are based on an image size of [1920, 1080]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    #displays the name of the boroughs of the city\n",
    "    if map_type == 'total':\n",
    "        #name of borough Manhattan\n",
    "        cv2.putText(image, 'Manhattan', (770, 360), \n",
    "            font, 0.8, (255, 255, 255), 1, cv2.LINE_AA) \n",
    "        #name of borough Brooklyn\n",
    "        cv2.putText(image, 'Brooklyn', (1130, 945), \n",
    "            font, 0.8,(255, 255, 255), 1, cv2.LINE_AA) \n",
    "        #name of borough Staten Island\n",
    "        cv2.putText(image, 'Staten Island', (595, 1030), \n",
    "            font, 0.8, (255, 255, 255), 1, cv2.LINE_AA) \n",
    "        #name of borough Queens\n",
    "        cv2.putText(image, 'Queens', (1480, 590), \n",
    "            font, 0.8, (255, 255, 255), 1, cv2.LINE_AA) \n",
    "        #name of borough Bronx\n",
    "        cv2.putText(image, 'Bronx', (1370, 195), \n",
    "            font, 0.8, (255, 255, 255), 1, cv2.LINE_AA) \n",
    "    \n",
    "    else:\n",
    "        video_title = video_title + ' in ' + map_type\n",
    "\n",
    "    #displays the legend of the colour code\n",
    "    cv2.putText(image, 'Origin and destination', (35, 260), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.circle(image, (40, 290), 10, (141, 91, 67), -1)\n",
    "    cv2.putText(image, 'Identical', (60, 300), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.circle(image, (40, 320), 10, (135,162,34), -1)\n",
    "    cv2.putText(image, 'Distinct', (60, 330), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    #displays the title of the video\n",
    "    #cv2.putText(image, video_title, (500, 1050), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "\n",
    "def render_frame(frame, base_map, query_results, converted_shape_dict, map_type):\n",
    "\n",
    "        \n",
    "    #we make a copy of the map on which we will render the frame (each frame being\n",
    "    #rendered on a new copy)\n",
    "    map_rendered = base_map.copy()\n",
    "\n",
    "    #we get the value of the min and max number of passengers from the query result\n",
    "    min_passenger_itinerary = min(query_results, key=lambda x:x[2])\n",
    "    max_passenger_itinerary = max(query_results, key=lambda x:x[2])\n",
    "    max_passenger = max_passenger_itinerary[2]\n",
    "    min_passenger = min_passenger_itinerary[2]\n",
    "    \n",
    "    #we get each tuple from the query result, in the form (origin_id, dest_id, weight)\n",
    "    for itinerary in query_results:\n",
    "        zone_id_origin = convert_id_shape(itinerary[0])\n",
    "        zone_id_destination = convert_id_shape(itinerary[1])\n",
    "\n",
    "        weight = itinerary[2]\n",
    "        weight = compute_weight(map_type, weight, max_passenger)\n",
    "\n",
    "        #we get the coordinates of the center of the origin and the destination\n",
    "        origin_coords = converted_shape_dict[zone_id_origin]['center']\n",
    "        destination_coords = converted_shape_dict[zone_id_destination]['center']\n",
    "\n",
    "        if frame == 0:\n",
    "            #we start the rendering with the point at the origin\n",
    "            #we convert to int as to be able to plot the point with opencv\n",
    "            coords_point_to_draw = (int(origin_coords[0]), int(origin_coords[1]))\n",
    "\n",
    "        else:\n",
    "            #we extrapolate the position of the point between the origin and the\n",
    "            #destination, as to have the point move from origin to destination\n",
    "            #in 60 frames\n",
    "            coords_point_to_draw = interpolate_next_position(origin_coords, destination_coords, 60, frame)\n",
    "\n",
    "        x_point = coords_point_to_draw[0]\n",
    "        y_point = coords_point_to_draw[1]\n",
    "\n",
    "        if zone_id_origin == zone_id_destination:\n",
    "            colour = (141, 91, 67)\n",
    "        else:\n",
    "            colour = (135,162,34)\n",
    "\n",
    "        render_point_on_map(x_point, y_point, weight, map_rendered, colour)\n",
    "\n",
    "    return map_rendered, min_passenger, max_passenger\n",
    "\n",
    "\n",
    "def render_all_frames(render_frame_dict):\n",
    "    \n",
    "    #we extract the arguments we need from the input dictionary\n",
    "    query_dict = render_frame_dict['query_dict']\n",
    "    database = render_frame_dict['database']\n",
    "    base_map = render_frame_dict['base_map']\n",
    "    converted_shape_dict = render_frame_dict['converted_shape_dict']\n",
    "    map_type = render_frame_dict['map_type']\n",
    "    frames = render_frame_dict['frames']\n",
    "    \n",
    "    #we query the database\n",
    "    query = prepare_sql_query(query_dict)\n",
    "    query_results = make_sql_query(query, database)\n",
    "    \n",
    "    #we use the results of the query to render 60 frames\n",
    "    #we want to render an animation of 1 second per given date, at 60 fps. \n",
    "    for frame in range(0, 60):  \n",
    "        rendered_frame, min_pass, max_pass = render_frame(frame, base_map, query_results, \n",
    "                                                        converted_shape_dict, map_type)       \n",
    "        \n",
    "        #we display frame related text\n",
    "        display_specific_text(rendered_frame, query_dict['date'], map_type, min_pass, max_pass)\n",
    "        \n",
    "        frames.append(rendered_frame)\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def make_video_animation(frames, image_size, map_type):\n",
    "        \n",
    "    #Build the title for the animation\n",
    "    if map_type == 'total':\n",
    "        title = 'Animation_{}.avi'.format('NYC')\n",
    "    else:\n",
    "        title = 'Animation_{}.avi'.format(map_type)\n",
    "    \n",
    "    animation = cv2.VideoWriter(title, cv2.VideoWriter_fourcc(*'DIVX'), 30, image_size)\n",
    "    #video title, codec, fps, frame size\n",
    "\n",
    "    for i in range(len(frames)):\n",
    "        animation.write(frames[i])\n",
    "    \n",
    "    animation.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_animation_query_output(render_animation_dict):\n",
    "    \n",
    "    #We extract the variables we will need from the input dictionary\n",
    "    query_dict = render_animation_dict['query_dict']\n",
    "    base_map = render_animation_dict['base_map']\n",
    "    map_type = render_animation_dict['map_type']\n",
    "    shape_dict = render_animation_dict['shape_dict']\n",
    "    df_sf = render_animation_dict['df_sf']\n",
    "    database = render_animation_dict['database']\n",
    "    image_size = render_animation_dict['image_size']\n",
    "    render_single_borough = render_animation_dict['render_single_borough']\n",
    "    \n",
    "    if query_dict['filter_query_on_borough'] == False:\n",
    "        #in this case, we may want the base map to be reduced to map_type, but the query\n",
    "        #to be performed on the whole city - thus we want to represent points that may\n",
    "        #not be inside the shape of the reduced base map\n",
    "        projection = render_animation_dict['projection']\n",
    "        converted_shape_dict = convert_shape_boundaries(shape_dict, projection)\n",
    "    \n",
    "    else:\n",
    "        #we isolate the set of zones we want to draw points for in the right coordinate system\n",
    "        converted_shape_dict, projection = get_shape_set_to_draw(map_type, shape_dict, df_sf, image_size)\n",
    "\n",
    "\n",
    "    #we build a dictionary for the details of the rendering of each frame\n",
    "    render_frame_dict = {'query_dict':query_dict,'database':database,\n",
    "                         'base_map':base_map,'converted_shape_dict':converted_shape_dict,\n",
    "                         'map_type':map_type,'frames':[]}\n",
    "    \n",
    "    #we render frames depending on the results of the query and the period inputted\n",
    "    \n",
    "    if query_dict['date'] == 'loop_through_period':\n",
    "        #if we have the flag loop_through_period in the query dict, it means the period\n",
    "        #set for the query is multiple dates, therefore we need to render multiple times\n",
    "        #60 frames\n",
    "        period = render_animation_dict['period']\n",
    "        daterange = pd.date_range(period[0],period[1])\n",
    "        #we run queries for each date in the daterange specified\n",
    "        for single_date in daterange: \n",
    "            date = pd.to_datetime(single_date)\n",
    "            if query_dict['specific_weekdays'] == 'on_specific_weekdays':\n",
    "                weekdays = render_animation_dict['weekdays']\n",
    "                \n",
    "                #we check if the date of the daterange matches the weekday(s) we target\n",
    "                if date_timestamp.dayofweek in weekdays:\n",
    "                    single_date = date.date().strftime('%Y-%m-%d')\n",
    "                    query_dict['date'] = single_date\n",
    "                    frames = render_all_frames(render_frame_dict)\n",
    "                    render_frame_dict['frames'] = frames\n",
    "                    \n",
    "                else:\n",
    "                    #if a date in the range is not among the weekdays we want, we skip it\n",
    "                    continue\n",
    "            else:\n",
    "                single_date = date.date().strftime('%Y-%m-%d')\n",
    "                query_dict['date'] = single_date\n",
    "                frames = render_all_frames(render_frame_dict)\n",
    "                render_frame_dict['frames'] = frames\n",
    "    \n",
    "    else:\n",
    "        #we have a single period (i.e. one single day) to render results for and we \n",
    "        #just render 60 frames for this period\n",
    "        #just in case we check that there is no mismatch between the single day and the\n",
    "        #argument containing specific weekdays restrictions if any\n",
    "        \n",
    "        if query_dict['specific_weekdays'] == 'on_specific_weekdays':\n",
    "                weekdays = render_animation_dict['weekdays']\n",
    "                \n",
    "                #we check if the date of the daterange matches the weekday(s) we target\n",
    "                date = pd.Timestamp(query_dict['date'])\n",
    "                \n",
    "                if date.dayofweek in weekdays:\n",
    "                    frames = render_all_frames(render_frame_dict)\n",
    "        \n",
    "                else:\n",
    "                    print(\"The date selected does not match the weekday(s) indicated. \"\n",
    "                        \"Please select either an interval ('time_granularity':'period') \"\n",
    "                        \"or a valid weekday(s) list.\")\n",
    "        \n",
    "        else:\n",
    "            frames = render_all_frames(render_frame_dict)\n",
    "    \n",
    "    if map_type == 'total':\n",
    "        print('Rendering the results for NYC...')\n",
    "    else:\n",
    "        print('Rendering the results for {}...'.format(map_type))\n",
    "    \n",
    "    #we compile the video from all frames\n",
    "    make_video_animation(frames, image_size, map_type)\n",
    "    \n",
    "\n",
    "    if map_type == 'total':\n",
    "        print('The video for NYC has been rendered')\n",
    "    else:\n",
    "        print('The video for {} has been rendered'.format(map_type))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python script**\n",
    "\n",
    "We can the define the python script that will rely on all functions provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flow_animation(animation_dict):\n",
    "    #we extract the variables from the input dictionary\n",
    "    shp_path = animation_dict['shp_path']\n",
    "    image_size = animation_dict['image_size']\n",
    "    map_to_render = animation_dict['map_to_render']\n",
    "    render_single_borough = animation_dict['render_single_borough']\n",
    "    title = animation_dict['title']\n",
    "    database = animation_dict['db']\n",
    "    data_table = animation_dict['data_table']\n",
    "    lookup_table = animation_dict['lookup_table']\n",
    "    aggregated_result = animation_dict['aggregated_result']\n",
    "    filter_query_on_borough = animation_dict['filter_query_on_borough']\n",
    "    time_granularity = animation_dict['time_granularity']\n",
    "    period = animation_dict['period']\n",
    "    weekdays = animation_dict['weekdays']\n",
    "    \n",
    "    #First import the shapefile and build the boundaries dictionary\n",
    "    print('Building the base map...')\n",
    "    shp_path = shp_path\n",
    "    sf_nyc = shp.Reader(shp_path)\n",
    "    df_sf = shp_to_df(sf_nyc)\n",
    "    shape_boundaries = process_shape_boundaries(df_sf, sf_nyc)\n",
    "    \n",
    "    #optional fool_proof check\n",
    "    #if filter on borough is not False, then it contains the name of a borouhgh, \n",
    "    #that happens to be the only one we want to use to draw the base map\n",
    "    #so we ignore the input of the user in the map_to_render argument\n",
    "    if filter_query_on_borough !=False:\n",
    "        map_to_render = [filter_query_on_borough]\n",
    "    \n",
    "    #Draw the base map and keep it in a saved variable\n",
    "    base_maps = []\n",
    "    if len(map_to_render) == 1:\n",
    "        map_type = map_to_render[0]\n",
    "        #we want to render on a single map\n",
    "        draw_dict = {'image_size':image_size, 'render_single_borough':render_single_borough, \n",
    "                     'map_type':map_type, 'title':title, \n",
    "                     'shape_dict':shape_boundaries, 'df_sf':df_sf}\n",
    "        base_map, projection = draw_base_map(draw_dict)\n",
    "        base_maps.append((map_type, base_map, projection))\n",
    "    \n",
    "    else:\n",
    "        #we want to render multiple animations at once, for different base maps\n",
    "        for single_map in map_to_render:\n",
    "            map_type = single_map\n",
    "            draw_dict = {'image_size':image_size, 'render_single_borough':render_single_borough,\n",
    "                         'map_type':map_type, 'title':title, \n",
    "                         'shape_dict':shape_boundaries, 'df_sf':df_sf}\n",
    "            base_map, projection = draw_base_map(draw_dict)\n",
    "            base_maps.append((map_type, base_map, projection))\n",
    "    \n",
    "    #we define the render_animation_dict\n",
    "    render_animation_dict = {'time_granularity':time_granularity, 'period':period,  \n",
    "                             'weekdays':weekdays,'filter_query_on_borough':filter_query_on_borough, \n",
    "                             'image_size':image_size,'shape_dict':shape_boundaries, \n",
    "                             'df_sf':df_sf,'database':database, 'data_table':data_table, \n",
    "                             'lookup_table':lookup_table,'aggregated_result':aggregated_result,\n",
    "                             'render_single_borough':render_single_borough,\n",
    "                             'video_title':title}\n",
    "\n",
    "    print('Querying the dabase...')\n",
    "         \n",
    "    query_dict = build_query_dict(render_animation_dict)\n",
    "    render_animation_dict['query_dict'] = query_dict\n",
    "    \n",
    "    #we render the animation!\n",
    "    for map_type, base_map, projection in base_maps:\n",
    "        #we add variabled to the render frame dictionary\n",
    "        render_animation_dict['base_map'] = base_map\n",
    "        render_animation_dict['projection'] = projection\n",
    "        render_animation_dict['map_type'] = map_type\n",
    "\n",
    "        render_animation_query_output(render_animation_dict)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses as an input a dictionary, which structure is as follows:\n",
    "\n",
    "animation_dict = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                  'map_to_render':['total', 'Manhattan'],'render_single_borough':False,\n",
    "                  'filter_query_on_borough':False,\n",
    "                  'title':'General flow of passengers in 2018', \n",
    "                  'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                 'lookup_table':'taxi_zone_lookup_table', 'aggregated_result':'count',\n",
    "                 'time_granularity':'period', 'period':['2018-01-01','2018-01-03'],  \n",
    "                 'weekdays':[]}\n",
    "                 \n",
    "**Arguments:**\n",
    "- shp_path: the path to the shapefile used to render the base map\n",
    "- image_size: the size of each frame [width, height]\n",
    "- map_to_render: the base map(s) we want animations for. Always provided as a list. If more than one item is in the list, one animation per item will be rendered.\n",
    "- render_single_borough: flag to indicate whether we want to focus on a single borough and render *only* the borough (in this case True), or if we simply want to center and zoom on a borough but still render the rest of the map (in this case False)\n",
    "- filter_query_on_borough: whether we want to execute the query filtering on a borough, or if we want the results for the whole city\n",
    "- title: the title to display in the animation\n",
    "- db: the name of the database to connect to\n",
    "- data_table: the table in which to fetch the data (in our case, the table in which we have the data for 2018)\n",
    "- lookup_table: the taxi zone lookup table, to match a zone id with the name of a borough\n",
    "- aggregated_result: the type of result we want from the query, either avg or count (note that the query results will always be structured 'PULocationID', 'DOLocationID', aggregated_result). \n",
    "- time_granularity: if we want to filter for specific weekdays or we want results for every day in the provided period\n",
    "- period: the time interval to consider for the query. If we want for a single date, start and end date should be inputted the same.\n",
    "- weekdays: the index of the weekday(s) we want data for (0 being Monday, 6 being Sunday). If we want to filter on one or more weekday, time_granularity should be set to 'on_specific_weekdays'. If we we do not want to filter on any weekday, time_granularity should be set to 'period' and the array of weekdays left empty []. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the base map...\n",
      "Querying the dabase...\n",
      "Rendering the results for NYC...\n",
      "The video for NYC has been rendered\n",
      "Rendering the results for Manhattan...\n",
      "The video for Manhattan has been rendered\n",
      "Rendering the results for Bronx...\n",
      "The video for Bronx has been rendered\n",
      "Rendering the results for Queens...\n",
      "The video for Queens has been rendered\n",
      "Rendering the results for Staten Island...\n",
      "The video for Staten Island has been rendered\n",
      "Rendering the results for Brooklyn...\n",
      "The video for Brooklyn has been rendered\n"
     ]
    }
   ],
   "source": [
    "animation_dict = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                  'map_to_render':['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn'],\n",
    "                  'render_single_borough':False,\n",
    "                  'filter_query_on_borough':False,\n",
    "                  'title':'General flow of passengers on weekdays in 2018', \n",
    "                  'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                 'lookup_table':'taxi_zone_lookup_table', 'aggregated_result':'count',\n",
    "                 'time_granularity':'period', 'period':['2018-01-01','2018-01-01'],  \n",
    "                 'weekdays':[0, 1, 2, 3, 4]}\n",
    "\n",
    "make_flow_animation(animation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Building a python script - part 2 (heat maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for this second rendering option, there is a lot we can reuse from the animation logic. The idea of this second visualisation is to render four heat maps per zone:\n",
    "- incoming flow\n",
    "- outgoing flow\n",
    "- difference in incoming flow between weekdays and weekends\n",
    "- difference in outgoing flow beteen weekdays and weekends\n",
    "\n",
    "Note that we are going to work with average or count of the number of passengers on the period selected by the user. So say we want the map for 2018 with the aggregated_result set to avg, we are going to average the total number of passenger in 2018, splitted per incoming and outgoing flow. If aggregated_result is set to count, we will simply sum the counts over the year.\n",
    "Likewise for the comparison of the weekdays and weekends, we will average the number of passengers of weekdays on the whole period, and subtract to it the number of passengers on weekends. Which means that if we have a positive value, there are more people traveling on weekdays, and if we have a negative value, there are more people traveling on weekends. \n",
    "\n",
    "\n",
    "What we will want to do is:\n",
    "- render a base map: either for the whole city, or solely for the borough in which we have the zone we are focusing on.\n",
    "- make four queries\n",
    "    - average on the period of the number of passengers grouped by *pick up* location ID -> we will look at *outgoing* flow\n",
    "    - average on the period of the number of passengers grouped by *drop off* location ID -> we will look at *incoming* flow\n",
    "    - difference between the average on the period on weekdays and weekends of the number of passengers grouped by *pick up* location ID -> we will look at average difference of *outgoing* flow between weekdays and weekends \n",
    "    - difference between the average on the period on weekdays and weekends of the number of passengers grouped by *drop off* location ID -> we will look at average difference of *incoming* flow between weekdays and weekends \n",
    "- draw the result maps\n",
    "\n",
    "As a result, we are going to render quite a lot of map! (5 maps per zone (one focused on the borough, one focused on the zone), 263 zones at most, so more than 1000 maps!). To make browsing easier, we will make the maps available on a web page with a dropdown list to select and display the desired map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the missing functions (those specific to the rendering oh the heat maps). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-67-5a3b69f4f79a>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-5a3b69f4f79a>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    if type(date) == str:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def prepare_heat_map_sql_query(query_dict):\n",
    "\n",
    "    {'data_table': 'taxi_rides_2018', \n",
    "     'lookup_table': 'taxi_zone_lookup_table', \n",
    "     'aggregated_result': 'avg', \n",
    "     'filter_query_on_borough': False, \n",
    "     'date': ['2018-01-01', '2018-01-02'], \n",
    "     'specific_weekdays': 'weekdays_vs_weekends'}\n",
    "    \n",
    "    #We extract the variables we will need from the input dictionary\n",
    "    data_table = query_dict['data_table']\n",
    "    lookup_table = query_dict['lookup_table']\n",
    "    aggregated_result = query_dict['aggregated_result']\n",
    "    date = query_dict['date']\n",
    "    filter_query_on_borough = query_dict['filter_query_on_borough']\n",
    "    weekdays_vs_weekends = query_dict['weekdays_vs_weekends']\n",
    "     \n",
    "    #first we synthesise what we want to fetch\n",
    "    if aggregated_result == 'count':\n",
    "        #we will want to return the sum of count on the period\n",
    "        aggregated_result = 'COUNT(passenger_count)'\n",
    "    elif aggregated_result == 'avg':\n",
    "        #we will want to return the average of count on the period\n",
    "        aggregated_result = '(COUNT(passenger_count)'\n",
    "    \n",
    "    #we prepare the period statements\n",
    "    if weekdays_vs_weekends == 'weekdays_vs_weekends':\n",
    "        #in this case we want to query 'separataly' the values in weekdays and weekends\n",
    "        #and make a difference on the average of the aggregated_result on the period\n",
    "        \n",
    "    if type(date) == str:\n",
    "        #in this case, we want the result on a single day\n",
    "    \n",
    "    else:\n",
    "        #we provided a time interval we want the average of the aggregated_result on the\n",
    "        #period\n",
    "        \n",
    "    \n",
    "    #avg on total period without borough filter\n",
    "    query = (\"SELECT pu_id, do_id, AVG(aggregated_result) \\\n",
    "             FROM \\\n",
    "                 (SELECT PULocationID pu_id, DOLocationID do_id, \\\n",
    "                         pickup_date date, COUNT(passenger_count) {0} \\\n",
    "                 FROM {1} AS tr_2018 \\\n",
    "                 WHERE pickup_date BETWEEN {2} AND {3} \\\n",
    "                 GROUP BY pu_id, do_id, date) as tab_1 \\\n",
    "             GROUP BY pu_id, do_id\").format(aggregated_result, data_table, start_date, \n",
    "                                            end_date)\n",
    "    \n",
    "    \n",
    "    #avg on total period with borough filter\n",
    "    query = (\"SELECT pu_id, do_id, AVG(aggregated_result) \\\n",
    "            FROM \\\n",
    "                 (SELECT PULocationID pu_id, DOLocationID do_id, \\\n",
    "                         pickup_date date, COUNT(passenger_count) {0} \\\n",
    "                 FROM {1} AS tr_2018 \\\n",
    "                 WHERE pickup_date BETWEEN {2} AND {3} \\\n",
    "                 GROUP BY pu_id, do_id, date) as tab_1 \\\n",
    "            JOIN {3} lookup_pu\\\n",
    "            ON lookup_pu.LocationID = tab_1.pu_id \\\n",
    "            JOIN {3} lookup_do \\\n",
    "            ON lookup_do.LocationID = tab_1.do_id \\\n",
    "            WHERE lookup_pu.borough_name = '{5}' AND lookup_do.borough_name = '{5}'\\\n",
    "            GROUP BY pu_id, do_id\").format(aggregated_result, data_table, start_date, \n",
    "                                            end_date, lookup_table, filter_query_on_borough)\n",
    "    \n",
    "    \n",
    "    #diff avg on total period between weekdays and weekends\n",
    "    query = (\"SELECT pu_id, do_id, AVG(aggregated_result) \\\n",
    "             FROM \\\n",
    "                 (SELECT PULocationID pu_id, DOLocationID do_id, \\\n",
    "                         pickup_date date, COUNT(passenger_count) {0} \\\n",
    "                 FROM {1} AS tr_2018 \\\n",
    "                 WHERE pickup_date BETWEEN {2} AND {3} AND pickup_weekday IN (0, 1, 2, 3, 4) \\\n",
    "                 GROUP BY pu_id, do_id, date) as weekday\\\n",
    "             JOIN (SELECT PULocationID pu_id, DOLocationID do_id, \\\n",
    "                 pickup_date date, COUNT(passenger_count) {0} \\\n",
    "                 FROM {1} AS tr_2018 \\\n",
    "                 WHERE pickup_date BETWEEN {2} AND {3} AND pickup_weekday IN (5, 6) \\\n",
    "                 GROUP BY pu_id, do_id, date) as weekend\\\n",
    "             \\\n",
    "             GROUP BY do_id, pu_id\").format(aggregated_result, data_table, start_date, \n",
    "                                            end_date)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #avg on total period for incoming\n",
    "    query = (\"SELECT pu_id, do_id, AVG(aggregated_result) \\\n",
    "             FROM \\\n",
    "                 (SELECT PULocationID pu_id, DOLocationID do_id, \\\n",
    "                         pickup_date date, COUNT(passenger_count) aggregated_result \\\n",
    "                 FROM taxi_rides_2018 AS tr_2018 \\\n",
    "                 WHERE pickup_date BETWEEN '2018-01-01 00:00:00' AND '2018-01-02 00:00:00' \\\n",
    "                 GROUP BY pu_id, do_id, date) as tab_1 \\\n",
    "                 \n",
    "             \n",
    "             GROUP BY pu_id, do_id\")\n",
    "    \n",
    "    #then we work on the 'WHERE' statements and the JOIN \n",
    "    if filter_query_on_borough != False:\n",
    "        query = (\"SELECT pu_id, do_id, aggregated_result \\\n",
    "                 FROM (\\\n",
    "                    SELECT PULocationID pu_id, DOLocationID do_id, {0} aggregated_result\\\n",
    "                    FROM {1} tr_2018\\\n",
    "                    WHERE pickup_date = '{2}'\\\n",
    "                    GROUP BY pu_id, do_id\\\n",
    "                    ORDER by aggregated_result) AS tr_2018\\\n",
    "                 JOIN {3} lookup_pu\\\n",
    "                 ON lookup_pu.LocationID = tr_2018.pu_id \\\n",
    "                 JOIN {3} lookup_do \\\n",
    "                 ON lookup_do.LocationID = tr_2018.do_id \\\n",
    "                 WHERE lookup_pu.borough_name = '{4}' AND lookup_do.borough_name = '{4}'\".format\n",
    "                (aggregated_result, data_table, date, lookup_table, filter_query_on_borough))\n",
    "\n",
    "    else:\n",
    "        query = (\"SELECT PULocationID pu_id, DOLocationID do_id, {0} aggregated_result\\\n",
    "                    FROM {1} AS tr_2018\\\n",
    "                    WHERE pickup_date = '{2}'\\\n",
    "                    GROUP BY pu_id, do_id\".format(aggregated_result, data_table, date))\n",
    "\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_heat_map_query_output(render_heat_map_dict):\n",
    "    \n",
    "    #We extract the variables we will need from the input dictionary\n",
    "    query_dict = render_heat_map_dict['query_dict']\n",
    "    base_map = render_heat_map_dict['base_map']\n",
    "    map_type = render_heat_map_dict['map_type']\n",
    "    shape_dict = render_heat_map_dict['shape_dict']\n",
    "    df_sf = render_heat_map_dict['df_sf']\n",
    "    database = render_heat_map_dict['database']\n",
    "    image_size = render_heat_map_dict['image_size']\n",
    "\n",
    "\n",
    "    if query_dict['filter_query_on_borough'] == False:\n",
    "        #in this case, we may want the base map to be reduced to map_type, but the query\n",
    "        #to be performed on the whole city - thus we want to represent points that may\n",
    "        #not be inside the shape of the reduced base map\n",
    "        projection = render_heat_map_dict['projection']\n",
    "        converted_shape_dict = convert_shape_boundaries(shape_dict, projection)\n",
    "    \n",
    "    else:\n",
    "        #we isolate the set of zones we want to draw points for in the right coordinate system\n",
    "        converted_shape_dict, projection = get_shape_set_to_draw(map_type, shape_dict, df_sf, image_size)\n",
    "\n",
    "\n",
    "    #we build a dictionary for the details of the rendering of each frame\n",
    "    render_map_dict = {'query_dict':query_dict,'database':database,'base_map':base_map,\n",
    "                       'converted_shape_dict':converted_shape_dict,'map_type':map_type}\n",
    "    \n",
    "    if query_dict['date'] == 'loop_through_period':\n",
    "        #if we have the flag loop_through_period in the query dict, it means the period\n",
    "        #set for the query is multiple dates, therefore we want the query to return an\n",
    "        #average on a time interval, and not on a single date\n",
    "        period = render_heat_map_dict['period']\n",
    "        daterange = pd.date_range(period[0],period[1])\n",
    "        query_dict['date'] = period\n",
    "        \n",
    "        \n",
    "        if query_dict['specific_weekdays'] == 'weekdays_vs_weekends':\n",
    "            return None\n",
    "            #we query the difference between the average on weekdays and weekends\n",
    "            #on the whole period\n",
    "            #query grouped by pu_id\n",
    "            #query grouped by do_id\n",
    "        \n",
    "        return None       \n",
    "    print(query_dict)\n",
    "           \n",
    "        #we query and average on the whole period\n",
    "        #query grouped by pu_id\n",
    "        #query grouped by do_id\n",
    "        \n",
    "\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        date = pd.to_datetime(single_date)\n",
    "        single_date = date.date().strftime('%Y-%m-%d')\n",
    "        query_dict['date'] = single_date\n",
    "            \n",
    "            \n",
    "#we run queries for each date in the daterange specified\n",
    "        for single_date in daterange: \n",
    "            date = pd.to_datetime(single_date)\n",
    "            if query_dict['specific_weekdays'] == 'on_specific_weekdays':\n",
    "                weekdays = render_animation_dict['weekdays']\n",
    "                \n",
    "                #we check if the date of the daterange matches the weekday(s) we target\n",
    "                if date_timestamp.dayofweek in weekdays:\n",
    "                    single_date = date.date().strftime('%Y-%m-%d')\n",
    "                    query_dict['date'] = single_date\n",
    "                    frames = render_all_frames(render_frame_dict)\n",
    "                    render_frame_dict['frames'] = frames\n",
    "                    \n",
    "                else:\n",
    "                    #if a date in the range is not among the weekdays we want, we skip it\n",
    "                    continue\n",
    "            else:\n",
    "                single_date = date.date().strftime('%Y-%m-%d')\n",
    "                query_dict['date'] = single_date\n",
    "                frames = render_all_frames(render_frame_dict)\n",
    "                render_frame_dict['frames'] = frames\n",
    "    \n",
    "    else:\n",
    "        #we have a single period (i.e. one single day) to render results for and we \n",
    "        #just render 60 frames for this period\n",
    "        #just in case we check that there is no mismatch between the single day and the\n",
    "        #argument containing specific weekdays restrictions if any\n",
    "        \n",
    "        if query_dict['specific_weekdays'] == 'on_specific_weekdays':\n",
    "                weekdays = render_animation_dict['weekdays']\n",
    "                \n",
    "                #we check if the date of the daterange matches the weekday(s) we target\n",
    "                date = pd.Timestamp(query_dict['date'])\n",
    "                \n",
    "                if date.dayofweek in weekdays:\n",
    "                    frames = render_all_frames(render_frame_dict)\n",
    "        \n",
    "                else:\n",
    "                    print(\"The date selected does not match the weekday(s) indicated. \"\n",
    "                        \"Please select either an interval ('time_granularity':'period') \"\n",
    "                        \"or a valid weekday(s) list.\")\n",
    "        \n",
    "        else:\n",
    "            frames = render_all_frames(render_frame_dict)\n",
    "    \n",
    "    if map_type == 'total':\n",
    "        print('Rendering the results for NYC...')\n",
    "    else:\n",
    "        print('Rendering the results for {}...'.format(map_type))\n",
    "    \n",
    "    #we compile the video from all frames\n",
    "    make_video_animation(frames, image_size, map_type)\n",
    "    \n",
    "\n",
    "    if map_type == 'total':\n",
    "        print('The video for NYC has been rendered')\n",
    "    else:\n",
    "        print('The video for {} has been rendered'.format(map_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heat_map(heat_map_dict):\n",
    "    \n",
    "    #we extract the variables from the input dictionary\n",
    "    shp_path = heat_map_dict['shp_path']\n",
    "    image_size = heat_map_dict['image_size']\n",
    "    map_to_render = heat_map_dict['map_to_render']\n",
    "    render_single_borough = heat_map_dict['render_single_borough']\n",
    "    title = heat_map_dict['title']\n",
    "    database = heat_map_dict['db']\n",
    "    data_table = heat_map_dict['data_table']\n",
    "    lookup_table = heat_map_dict['lookup_table']\n",
    "    aggregated_result = heat_map_dict['aggregated_result']\n",
    "    filter_query_on_borough = heat_map_dict['filter_query_on_borough']\n",
    "    period = heat_map_dict['period']\n",
    "    \n",
    "    if heat_map_dict['weekdays_vs_weekends']==True:\n",
    "        time_granularity = 'weekdays_vs_weekends'\n",
    "    else:\n",
    "        time_granularity = 'period'\n",
    "    \n",
    "    #First import the shapefile and build the boundaries dictionary\n",
    "    print('Building the base map...')\n",
    "    shp_path = shp_path\n",
    "    sf_nyc = shp.Reader(shp_path)\n",
    "    df_sf = shp_to_df(sf_nyc)\n",
    "    shape_boundaries = process_shape_boundaries(df_sf, sf_nyc)\n",
    "    \n",
    "    #fool_proof check\n",
    "    if render_single_borough == True:\n",
    "        #in this case we do not want to render the whole map of NYC, but only boroughs maps\n",
    "        if 'total' in map_to_render: \n",
    "            #so we remove 'total' from the list of maps to render if it was added by the user\n",
    "            map_to_render.remove('total')\n",
    "            \n",
    "    \n",
    "    #Draw the base map and keep it in a saved variable\n",
    "    base_maps = []\n",
    "    if len(map_to_render) == 1:\n",
    "        map_type = map_to_render[0]\n",
    "        #we want to render on a single map\n",
    "        draw_dict = {'image_size':image_size, 'render_single_borough':render_single_borough, \n",
    "                     'map_type':map_type, 'title':title, \n",
    "                     'shape_dict':shape_boundaries, 'df_sf':df_sf}\n",
    "        base_map, projection = draw_base_map(draw_dict)\n",
    "        base_maps.append((map_type, base_map, projection))\n",
    "    \n",
    "    else:\n",
    "        #we want to render multiple heat maps at once, for different base maps\n",
    "        for single_map in map_to_render:\n",
    "            map_type = single_map\n",
    "            draw_dict = {'image_size':image_size, 'render_single_borough':render_single_borough,\n",
    "                         'map_type':map_type, 'title':title, \n",
    "                         'shape_dict':shape_boundaries, 'df_sf':df_sf}\n",
    "            base_map, projection = draw_base_map(draw_dict)\n",
    "            base_maps.append((map_type, base_map, projection))\n",
    "    \n",
    "    \n",
    "    #we define the render_heat_map_dict    \n",
    "    render_heat_map_dict = {'time_granularity':time_granularity, 'period':period,  \n",
    "                             'image_size':image_size,'shape_dict':shape_boundaries, \n",
    "                             'df_sf':df_sf,'database':database, 'data_table':data_table, \n",
    "                             'lookup_table':lookup_table,'aggregated_result':aggregated_result,\n",
    "                             'title':title, 'filter_query_on_borough':filter_query_on_borough}\n",
    "    \n",
    "    print('Querying the dabase...')\n",
    "         \n",
    "    query_dict = build_query_dict(render_heat_map_dict)\n",
    "    render_heat_map_dict['query_dict'] = query_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #we render the heat maps!\n",
    "    for map_type, base_map, projection in base_maps:\n",
    "        #we add variabled to the render frame dictionary\n",
    "        render_heat_map_dict['base_map'] = base_map\n",
    "        render_heat_map_dict['projection'] = projection\n",
    "        render_heat_map_dict['map_type'] = map_type\n",
    "        \n",
    "        render_heat_map_query_output(render_heat_map_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the base map...\n",
      "Querying the dabase...\n",
      "{'data_table': 'taxi_rides_2018', 'lookup_table': 'taxi_zone_lookup_table', 'aggregated_result': 'avg', 'filter_query_on_borough': False, 'date': ['2018-01-01', '2018-01-02'], 'specific_weekdays': 'weekdays_vs_weekends'}\n",
      "{'data_table': 'taxi_rides_2018', 'lookup_table': 'taxi_zone_lookup_table', 'aggregated_result': 'avg', 'filter_query_on_borough': False, 'date': ['2018-01-01', '2018-01-02'], 'specific_weekdays': 'weekdays_vs_weekends'}\n",
      "{'data_table': 'taxi_rides_2018', 'lookup_table': 'taxi_zone_lookup_table', 'aggregated_result': 'avg', 'filter_query_on_borough': False, 'date': ['2018-01-01', '2018-01-02'], 'specific_weekdays': 'weekdays_vs_weekends'}\n",
      "{'data_table': 'taxi_rides_2018', 'lookup_table': 'taxi_zone_lookup_table', 'aggregated_result': 'avg', 'filter_query_on_borough': False, 'date': ['2018-01-01', '2018-01-02'], 'specific_weekdays': 'weekdays_vs_weekends'}\n",
      "{'data_table': 'taxi_rides_2018', 'lookup_table': 'taxi_zone_lookup_table', 'aggregated_result': 'avg', 'filter_query_on_borough': False, 'date': ['2018-01-01', '2018-01-02'], 'specific_weekdays': 'weekdays_vs_weekends'}\n"
     ]
    }
   ],
   "source": [
    "heat_map_dict = {'shp_path':shp_path, 'image_size':(1920,1080),'db':'nyc_taxi_rides', \n",
    "                 'data_table':'taxi_rides_2018','lookup_table':'taxi_zone_lookup_table', \n",
    "                 'aggregated_result':'count', 'weekdays_vs_weekends':True,\n",
    "                 'period':['2018-01-01','2018-01-02'], 'render_single_borough':False,\n",
    "                  'filter_query_on_borough':False,\n",
    "                  'map_to_render':['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn'],\n",
    "                  'title':'Title'} \n",
    "\n",
    "make_heat_map(heat_map_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - render the animations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to generate the animations. All the animations generated here are saved with the notebook. \n",
    "\n",
    "In general, the common arguments we are going to pass to the function are the following:\n",
    "- **shp_path** (same shapefile no matter what animation we are rendering)\n",
    "- **image_size**: [1920, 1080]\n",
    "- **db**: the nyc_taxi_rides database\n",
    "- **data_table**: the taxi_rides_2018 table\n",
    "- **lookup_table**: the taxi_zone_lookup_table table\n",
    "- **aggregated_result**: count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Animation 1 - over the year 2018**\n",
    "\n",
    "This animation is actually composed of a few videos: the flow of passengers everyday in 2018, for the whole city as well as one video per borough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify our specific arguments:\n",
    "- **map_to_render**: for the whole year, we will want to look at the whole city and each borough individually, so we set this to ['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn']\n",
    "- **render_single_borough**: let's set this to False, so we just focus and zoom on to the borough when rendering them separately\n",
    "- **filter_query_on_borough**: set to False so we make one query per day that we can reuse to render each animation individually\n",
    "- **title**: Let's stay simple, with 'General flow of passengers in 2018'. The name of the borough will be appended automatically to the title when rendering the borough-focused animation\n",
    "- **time_granularity**: we don't want a filter on specific weekdays, so we set this as 'period'\n",
    "- period: we want the whole year, so ['2018-01-01','2018-12-31']!\n",
    "- **weekdays**: we want for the whole year, so let's leave this as an empty array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the base map...\n",
      "\n",
      "\n",
      "Querying the dabase for Manhattan...\n",
      "Rendering the results for Manhattan...\n",
      "The video for Manhattan has been rendered\n",
      "\n",
      "\n",
      "Querying the dabase for Manhattan...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fe36a7939c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                        'weekdays':[]}\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmake_flow_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimation_dict_2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-ae02887136b0>\u001b[0m in \u001b[0;36mmake_flow_animation\u001b[0;34m(animation_dict)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                 'video_title':title}\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#we render the animation!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mrender_animation_query_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_animation_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2e5c11423791>\u001b[0m in \u001b[0;36mrender_animation_query_output\u001b[0;34m(render_animation_dict)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0msingle_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mquery_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_all_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_frame_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mrender_frame_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-71f302218093>\u001b[0m in \u001b[0;36mrender_all_frames\u001b[0;34m(render_frame_dict)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m#we query the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mquery_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m#we use the results of the query to render 60 frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b2ebfa282f88>\u001b[0m in \u001b[0;36mmake_sql_query\u001b[0;34m(query, database)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#execute the query...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# ...and store the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mysql/connector/cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    264\u001b[0m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[1;32m    265\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                                          raw_as_string=self._raw_as_string)\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             raise errors.get_mysql_exception(msg=exc.msg, errno=exc.errno,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    393\u001b[0m             self._cmysql.query(query,\n\u001b[1;32m    394\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                                raw_as_string=raw_as_string)\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shp_path = \"/Users/acoullandreau/Desktop/Taxi_rides_DS/taxi_zones/taxi_zones.shp\"\n",
    "\n",
    "animation_dict_2018 = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                       'map_to_render':['total', 'Manhattan'],\n",
    "                       'render_single_borough':False,\n",
    "                       'filter_query_on_borough':False,\n",
    "                       'title':'General flow of passengers in 2018', \n",
    "                       'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                       'lookup_table':'taxi_zone_lookup_table', 'aggregated_result':'count',\n",
    "                       'time_granularity':'period', 'period':['2018-01-01','2018-02-02'],  \n",
    "                       'weekdays':[]}\n",
    "\n",
    "make_flow_animation(animation_dict_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = \"/Users/acoullandreau/Desktop/Taxi_rides_DS/taxi_zones/taxi_zones.shp\"\n",
    "\n",
    "animation_dict_2018 = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                       'map_to_render':['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn'],\n",
    "                       'render_single_borough':False,\n",
    "                       'filter_query_on_borough':False,\n",
    "                       'title':'General flow of passengers in 2018', \n",
    "                       'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                       'lookup_table':'taxi_zone_lookup_table', 'aggregated_result':'count',\n",
    "                       'time_granularity':'period', 'period':['2018-01-01','2018-12-31'],  \n",
    "                       'weekdays':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-4f445572a7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_flow_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimation_dict_2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-129c55a17037>\u001b[0m in \u001b[0;36mmake_flow_animation\u001b[0;34m(animation_dict)\u001b[0m\n\u001b[1;32m     73\u001b[0m                                     'video_title':title}\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m#we render the animation!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mrender_animation_query_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_animation_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-0f74c7a0252d>\u001b[0m in \u001b[0;36mrender_animation_query_output\u001b[0;34m(render_animation_dict)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msingle_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mquery_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_all_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_frame_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mrender_frame_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-71f302218093>\u001b[0m in \u001b[0;36mrender_all_frames\u001b[0;34m(render_frame_dict)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         rendered_frame, min_pass, max_pass = render_frame(frame, base_map, query_results, \n\u001b[0;32m--> 155\u001b[0;31m                                                         converted_shape_dict, map_type)       \n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m#we display frame related text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-71f302218093>\u001b[0m in \u001b[0;36mrender_frame\u001b[0;34m(frame, base_map, query_results, converted_shape_dict, map_type)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m#destination, as to have the point move from origin to destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m#in 60 frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mcoords_point_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate_next_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords_point_to_draw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-51c182eb3dc5>\u001b[0m in \u001b[0;36minterpolate_next_position\u001b[0;34m(origin_coords, destination_coords, tot_frames, curr_frame)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#w and y to int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnew_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_origin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdelta_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnew_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_origin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdelta_y\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "make_flow_animation(animation_dict_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Animation 2 - over the year 2018, just weekdays**\n",
    "\n",
    "Same logic, let's create several videos per borough, but this time we want to see only weekdays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify our specific arguments:\n",
    "- **map_to_render**: for the whole year, we will want to look at the whole city and each borough individually, so we set this to ['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn']\n",
    "- **render_single_borough**: let's set this to False, so we just focus and zoom on to the borough when rendering them separately\n",
    "- **filter_query_on_borough**: set to False so we make one query per day that we can reuse to render each animation individually\n",
    "- **title**: Let's stay simple, with 'General flow of passengers on weekdays in 2018'. The name of the borough will be appended automatically to the title when rendering the borough-focused animation\n",
    "- **time_granularity**: we want a filter on specific weekdays, so we set this as 'on_specific_weekdays'\n",
    "- period: we want the whole year, so ['2018-01-01','2018-12-31']!\n",
    "- **weekdays**: we want only for week days, so [0, 1, 2, 3, 4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_dict_weekdays_2018 = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                                'map_to_render':['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn'],\n",
    "                                'render_single_borough':False,\n",
    "                                'filter_query_on_borough':False,\n",
    "                                'title':'General flow of passengers on weekdays in 2018', \n",
    "                                'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                                'lookup_table':'taxi_zone_lookup_table', \n",
    "                                'aggregated_result':'count',\n",
    "                                'time_granularity':'period', \n",
    "                                'period':['2018-01-01','2018-12-31'],  \n",
    "                                'weekdays':[0, 1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_flow_animation(animation_dict_weekdays_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Animation 3 - over the year 2018, just weekends**\n",
    "\n",
    "Same logic, let's create several videos per borough, but this time we want to see only weekends.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify our specific arguments:\n",
    "- **map_to_render**: for the whole year, we will want to look at the whole city and each borough individually, so we set this to ['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn']\n",
    "- **render_single_borough**: let's set this to False, so we just focus and zoom on to the borough when rendering them separately\n",
    "- **filter_query_on_borough**: set to False so we make one query per day that we can reuse to render each animation individually\n",
    "- **title**: Let's stay simple, with 'General flow of passengers on weekends in 2018'. The name of the borough will be appended automatically to the title when rendering the borough-focused animation\n",
    "- **time_granularity**: we want a filter on specific weekdays, so we set this as 'on_specific_weekdays'\n",
    "- period: we want the whole year, so ['2018-01-01','2018-12-31']!\n",
    "- **weekdays**: we want only for weekend days, so [5, 6]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_dict_weekends_2018 = {'shp_path':shp_path, 'image_size':(1920,1080), \n",
    "                                'map_to_render':['total', 'Manhattan', 'Bronx', 'Queens', 'Staten Island', 'Brooklyn'],\n",
    "                                'render_single_borough':False,\n",
    "                                'filter_query_on_borough':False,\n",
    "                                'title':'General flow of passengers on weekends in 2018', \n",
    "                                'db':'nyc_taxi_rides', 'data_table':'taxi_rides_2018',\n",
    "                                'lookup_table':'taxi_zone_lookup_table', \n",
    "                                'aggregated_result':'count',\n",
    "                                'time_granularity':'period', \n",
    "                                'period':['2018-01-01','2018-12, 31'],  \n",
    "                                'weekdays':[5, 6]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_flow_animation(animation_dict_weekends_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - render the heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a blank image\n",
    "blank_image = np.zeros((1080,1920,3), np.uint8) #Size of the image 1080 height, 1920 width, 3 channels of colour\n",
    "blank_image[:, :] = [255, 255, 255] #Sets the color to white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draws circle ; center, radius, colour, -1 to fill the shape\n",
    "cv2.circle(blank_image, (960, 540), 200, (0, 255, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(blank_image, 'zone_id', (960, 540), \n",
    "            font, 2, (255, 0, 0), 5, cv2.LINE_AA) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the image inside the Jupyter notebook\n",
    "plt.imshow(blank_image)\n",
    "plt.title(\"White Blank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show the image outside the notebook\n",
    "cv2.imshow(\"White Blank\", blank_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
